{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "groq_api_key=os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001AAD0286590>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001AAD0285600>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Anirudh, it's nice to meet you! üëã \\n\\nWhat can I do for you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 17, 'total_tokens': 44, 'completion_time': 0.049090909, 'prompt_time': 7.69e-05, 'queue_time': 0.022645967, 'total_time': 0.049167809}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-a4093588-6128-4ef6-ab5d-d2a150823f54-0', usage_metadata={'input_tokens': 17, 'output_tokens': 27, 'total_tokens': 44})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi my name is Anirudh \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Anirudh, you told me earlier! üòÑ  \\n\\nIs there anything else I can help you with?  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 58, 'total_tokens': 87, 'completion_time': 0.052727273, 'prompt_time': 0.001833202, 'queue_time': 0.020312906000000002, 'total_time': 0.054560475}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-81129f02-2c37-4ea1-a3f8-64fc5abb279f-0', usage_metadata={'input_tokens': 58, 'output_tokens': 29, 'total_tokens': 87})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content='Hi my name is Anirudh'),\n",
    "        AIMessage(content=\"Hello Anirudh! It's nice to meet you. \\n\\nWhat can I do for you today? üòä  \\n\\n\"),\n",
    "        HumanMessage(content='Hey what is my name?')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Message history\n",
    "#It will store the inputs which was passed earlier to maintain a converstaional history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{'session_id':'abcd'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content='Hi my name is Anirudh and i am a data scientist'),\n",
    "\n",
    "    ],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Anirudh.  \\n\\nI'm here to help, is there anything else you'd like to talk about?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 238, 'total_tokens': 268, 'completion_time': 0.054545455, 'prompt_time': 0.036650237, 'queue_time': 0.022045772999999998, 'total_time': 0.091195692}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-56f0f43e-5cc5-416d-a14a-c737aec90569-0', usage_metadata={'input_tokens': 238, 'output_tokens': 30, 'total_tokens': 268})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content='what is my name?'),\n",
    "\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "#This it is able to remember because it is using same configuration which is having same conversational history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Since I don't have access to any information about you, including your name, I can't tell you what it is.  \\n\\nIs there anything else I can help you with? üòä \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 64, 'total_tokens': 108, 'completion_time': 0.08, 'prompt_time': 0.002301869, 'queue_time': 0.020424368, 'total_time': 0.082301869}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-5e73bfd0-8a21-4781-bb71-40235d8cc0dc-0', usage_metadata={'input_tokens': 64, 'output_tokens': 44, 'total_tokens': 108})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check chainging the config with different session_id\n",
    "config2={\"configurable\":{'session_id':'mcc'}}\n",
    "\n",
    "with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content='what is my name?'),\n",
    "\n",
    "    ],\n",
    "    config=config2\n",
    ")\n",
    "#It doesnt have the history of messages hence not giving us correct output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",'You are a helpful assistant . Answer all the questions to the nest of your ability in {language}'),\n",
    "        MessagesPlaceholder(variable_name='messages')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§ï‡•É‡§∑‡•ç‡§£! üòä \\n\\n‡§Æ‡•Å‡§ù‡•á ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§ ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡•Ä ‡§™‡•Ç‡§∞‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•Ç‡§Å‡§ó‡§æ ‡§ï‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§∏‡§¨‡§∏‡•á ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§¶‡•á ‡§∏‡§ï‡•Ç‡§Å‡•§  \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 33, 'total_tokens': 94, 'completion_time': 0.110909091, 'prompt_time': 0.001822441, 'queue_time': 0.019432487999999998, 'total_time': 0.112731532}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-913e3214-e30c-4e6f-95bc-e69155a3c699-0', usage_metadata={'input_tokens': 33, 'output_tokens': 61, 'total_tokens': 94})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'messages':[HumanMessage(content='Hi my name is krish')],'language':'hindi'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history,input_messages_key='messages')\n",
    "\n",
    "config={'configurable':{'session_id':'agc'}}\n",
    "\n",
    "response=with_message_history.invoke({'messages':[HumanMessage(content='Hi my name is Anirudh')],'language':'hindi'},config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§Ö‡§®‡§ø‡§∞‡•Ç‡§¶‡•ç‡§ß! \\n\\n‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§∏‡•Å‡§®‡§ï‡§∞ ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§≤‡§ó‡§æ‡•§ üòä  \\n\\n‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡•à‡§∏‡•á ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?  \\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Manaing the conversational history because for a particular session if we keep on storing the history it will be out of bound to limit hence there \n",
    "is a rwquirement to limit the size of message you are passing in\"\"\"\n",
    "\n",
    "\"trim_message:helps to reduce how many messages we are sending to the model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "\n",
    "def token_counter(messages):\n",
    "    # Simple token count based on word count for illustration (replace with actual tokenization logic)\n",
    "    return sum(len(message.content.split()) for message in messages)\n",
    "\n",
    "# Define trimming function\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=20,\n",
    "    strategy='last',\n",
    "    token_counter=token_counter,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on='human'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(content='you are a good assistant'),\n",
    "    HumanMessage(content='hi ! I am mini alexa'),\n",
    "    AIMessage(content='Hi'),\n",
    "    HumanMessage(content='WHAT IS 1+1'),\n",
    "    AIMessage(content='2'),\n",
    "    HumanMessage(content='I LIKE CHICKEN'),\n",
    "    AIMessage(content='Nice'),\n",
    "    HumanMessage(content='I was born on 14 august'),\n",
    "    AIMessage(content='That is interesting'),\n",
    "    HumanMessage(content='I love playing outdoor sports'),\n",
    "    AIMessage(content='Nice ')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are a good assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I was born on 14 august', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='That is interesting', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I love playing outdoor sports', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Nice ', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)  #it took only less no of messags from history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As a helpful assistant, I don't have access to your personal information, including your ice cream preferences! \\n\\nWhat's your favorite flavor?  üç¶üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 57, 'total_tokens': 96, 'completion_time': 0.070909091, 'prompt_time': 0.001832991, 'queue_time': 0.020515058, 'total_time': 0.072742082}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-caf20417-6514-46ba-bb80-d51242952825-0', usage_metadata={'input_tokens': 57, 'output_tokens': 39, 'total_tokens': 96})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Connecting this trimmer to chain\n",
    "\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter('messages')|trimmer) \n",
    "    | prompt\n",
    "    |model\n",
    ")\n",
    "\n",
    "chain.invoke({\"messages\":messages + [HumanMessage(content='what ice cream do i like?')],\"language\":'English'})\n",
    "\n",
    "#So we are not getting because trimmer is removing that from history based on token size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history,input_messages_key='messages')\n",
    "config={\"configurable\":{'session_id':'abscdd'}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke({'messages':[HumanMessage(content='what ice cream do i eat')],'language':'hindi'},config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Ü‡§™‡§ï‡•ã ‡§ï‡§ø‡§∏ ‡§§‡§∞‡§π ‡§ï‡§æ ‡§Ü‡§á‡§∏‡§ï‡•ç‡§∞‡•Ä‡§Æ ‡§™‡§∏‡§Ç‡§¶ ‡§π‡•à? ü§î\\n\\n‡§Æ‡•Å‡§ù‡•á ‡§¨‡§§‡§æ‡§è‡§Ç ‡§§‡•ã ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•ã ‡§ï‡•Å‡§õ ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§¶‡•á ‡§∏‡§ï‡•Ç‡§Å! üç® \\n\\n‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™‡§ï‡•ã ‡§ï‡•ã‡§à ‡§ñ‡§æ‡§∏ ‡§´‡•ç‡§≤‡•á‡§µ‡§∞ ‡§™‡§∏‡§Ç‡§¶ ‡§π‡•à? (‡§ú‡•à‡§∏‡•á, ‡§ö‡•â‡§ï‡§≤‡•á‡§ü, ‡§∏‡•ç‡§ü‡•ç‡§∞‡•â‡§¨‡•á‡§∞‡•Ä, ‡§µ‡§®‡•Ä‡§≤‡§æ) üçìüç´üç¶ \\n‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§ï‡•ã‡§à ‡§ï‡•ç‡§∞‡§Ç‡§ö‡•Ä ‡§ü‡•á‡§ï‡•ç‡§∏‡§ö‡§∞ ‡§™‡§∏‡§Ç‡§¶ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç? (‡§ú‡•à‡§∏‡•á, ‡§¨‡§ü‡§∞‡§¨‡§ü‡§∞, ‡§®‡§ü‡•ç‡§∏) ü•ú\\n‡§Ø‡§æ ‡§´‡§ø‡§∞ ‡§Ü‡§™ ‡§ï‡•ã‡§à ‡§≤‡§ú‡•Ä‡§ú ‡§î‡§∞ ‡§ï‡•ç‡§∞‡•Ä‡§Æ‡•Ä ‡§Ü‡§á‡§∏‡§ï‡•ç‡§∞‡•Ä‡§Æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç? üç¶\\n\\n\\n‡§Ü‡§™‡§ï‡•á ‡§™‡§∏‡§Ç‡§¶ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•ã ‡§∏‡§π‡•Ä ‡§Ü‡§á‡§∏‡§ï‡•ç‡§∞‡•Ä‡§Æ ‡§∏‡•Å‡§ù‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å! üòä\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
